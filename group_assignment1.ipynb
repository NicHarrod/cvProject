{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import io # Input/Output Module\n",
    "import os # OS interfaces\n",
    "import cv2 # OpenCV package\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "from urllib import request # module for opening HTTP requests\n",
    "from matplotlib import pyplot as plt # Plotting library\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import List, Tuple\n",
    "from skimage.feature import hog\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "# train = pd.read_csv(\n",
    "#     '/kaggle/input/kul-computer-vision-ga-1-2025/train_set.csv', index_col = 0)\n",
    "# train.index = train.index.rename('id')\n",
    "\n",
    "# test = pd.read_csv(\n",
    "#     '/kaggle/input/kul-computer-vision-ga-1-2025/test_set.csv', index_col = 0)\n",
    "# test.index = test.index.rename('id')\n",
    "\n",
    "train = pd.read_csv(\n",
    "    'Dataset/train_set.csv', index_col = 0)\n",
    "train.index = train.index.rename('id')\n",
    "\n",
    "test = pd.read_csv(\n",
    "    'Dataset/test_set.csv', index_col = 0)\n",
    "test.index = test.index.rename('id')\n",
    "\n",
    "# read the images as numpy arrays and store in \"img\" column\n",
    "# train['img'] = [cv2.cvtColor(np.load('/kaggle/input/kul-computer-vision-ga-1-2025/train/train_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "#                 for index, row in train.iterrows()]\n",
    "\n",
    "# test['img'] = [cv2.cvtColor(np.load('/kaggle/input/kul-computer-vision-ga-1-2025/test/test_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "#                 for index, row in test.iterrows()]\n",
    "  \n",
    "train['img'] = [cv2.cvtColor(np.load('Dataset/train/train_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "                for index, row in train.iterrows()]\n",
    "\n",
    "test['img'] = [cv2.cvtColor(np.load('Dataset/test/test_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n",
    "                for index, row in test.iterrows()]\n",
    "  \n",
    "\n",
    "train_size, test_size = len(train),len(test)\n",
    "\n",
    "\"The training set contains {} examples, the test set contains {} examples.\".format(train_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: this dataset is a subset of the* [*VGG face dataset*](https://www.robots.ox.ac.uk/~vgg/data/vgg_face/).\n",
    "\n",
    "## 0.2. A first look\n",
    "Let's have a look at the data columns and class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training set contains an identifier, name, image information and class label\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test set only contains an identifier and corresponding image information.\n",
    "\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class distribution in the training set:\n",
    "train.groupby('name').agg({'img':'count', 'class': 'max'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that **Jesse is assigned the classification label 1**, and **Mila is assigned the classification label 2**. The dataset also contains 20 images of **look alikes (assigned classification label 0)** and the raw images. \n",
    "\n",
    "## 0.3. Preprocess data\n",
    "### 0.3.1 Example: HAAR face detector\n",
    "In this example we use the [HAAR feature based cascade classifiers](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html) to detect faces, then the faces are resized so that they all have the same shape. If there are multiple faces in an image, we only take the first one. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> You can write temporary files to <code>/kaggle/temp/</code> or <code>../../tmp</code>, but they won't be saved outside of the current session\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAARPreprocessor():\n",
    "    \"\"\"Preprocessing pipeline built around HAAR feature based cascade classifiers. \"\"\"\n",
    "    \n",
    "    def __init__(self, path, face_size):\n",
    "        self.face_size = face_size\n",
    "        file_path = os.path.join(path, \"haarcascade_frontalface_default.xml\")\n",
    "        if not os.path.exists(file_path): \n",
    "            if not os.path.exists(path):\n",
    "                os.mkdir(path)\n",
    "            self.download_model(file_path)\n",
    "        \n",
    "        self.classifier = cv2.CascadeClassifier(file_path)\n",
    "  \n",
    "    def download_model(self, path):\n",
    "        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/\"\\\n",
    "            \"haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        \n",
    "        with request.urlopen(url) as r, open(path, 'wb') as f:\n",
    "            f.write(r.read())\n",
    "            \n",
    "    def detect_faces(self, img):\n",
    "        \"\"\"Detect all faces in an image.\"\"\"\n",
    "        \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return self.classifier.detectMultiScale(\n",
    "            img_gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "        \n",
    "    def extract_faces(self, img):\n",
    "        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n",
    "        \n",
    "        faces = self.detect_faces(img)\n",
    "\n",
    "        return [img[y:y+h, x:x+w] for (x, y, w, h) in faces]\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize_size(faces: List[np.ndarray]) -> Tuple[List[np.ndarray], Tuple[int, int]]:\n",
    "        valid_faces = []\n",
    "        for face in faces:\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "            if face.dtype != np.uint8:\n",
    "                if face.dtype == np.float32 or face.dtype == np.float64:\n",
    "                    face = (face * 255).astype(np.uint8)\n",
    "                else:\n",
    "                    face = cv2.normalize(face, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            valid_faces.append(face)\n",
    "        if not valid_faces:\n",
    "            return [], (0, 0)\n",
    "        \n",
    "        min_height = min(face.shape[0] for face in faces if face.size > 0)\n",
    "        min_width = min(face.shape[1] for face in faces if face.size > 0)\n",
    "        std_faces = [cv2.resize(face, (min_width, min_height)) for face in valid_faces]\n",
    "        return std_faces, (min_height, min_width)\n",
    "    \n",
    "    def preprocess(self, data_row):\n",
    "        faces = self.extract_faces(data_row['img'])\n",
    "        \n",
    "        # if no faces were found, return None\n",
    "        if len(faces) == 0:\n",
    "            nan_img = np.empty(self.face_size + (3,))\n",
    "            nan_img[:] = np.nan\n",
    "            return nan_img\n",
    "        # only return the first face\n",
    "        return cv2.resize(faces[0], self.face_size, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "    def __call__(self, data):\n",
    "        return np.stack([self.preprocess(row) for _, row in data.iterrows()]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise**\n",
    "\n",
    "Let's plot a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter to play with \n",
    "FACE_SIZE = (100, 100)\n",
    "\n",
    "def plot_image_sequence(data, n, imgs_per_row=7):\n",
    "    n_rows = 1 + int(n/(imgs_per_row+1))\n",
    "    n_cols = min(imgs_per_row, n)\n",
    "\n",
    "    f,ax = plt.subplots(n_rows,n_cols, figsize=(10*n_cols,10*n_rows))\n",
    "    for i in range(n):\n",
    "        if n == 1:\n",
    "            ax.imshow(data[i])\n",
    "        elif n_rows > 1:\n",
    "            ax[int(i/imgs_per_row),int(i%imgs_per_row)].imshow(data[i])\n",
    "        else:\n",
    "            ax[int(i%n)].imshow(data[i])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#preprocessed data \n",
    "preprocessor = HAARPreprocessor(path = '../../tmp', face_size=FACE_SIZE)\n",
    "\n",
    "data_X, data_y = preprocessor(train), train['class'].values\n",
    "test_X = preprocessor(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces(faces: List[np.array]):\n",
    "    \"\"\"\"\n",
    "    Another function for visualization.\n",
    "    \"\"\"\n",
    "    images_per_row = 5\n",
    "    num_images = len(faces)\n",
    "    num_rows = num_images // images_per_row + 1\n",
    "\n",
    "    plt.figure(figsize=(15, 3 * num_rows))\n",
    "\n",
    "    for i, img in enumerate(faces):\n",
    "        plt.subplot(num_rows, images_per_row, i + 1) \n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Image {i + 1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot faces of Michael and Sarah\n",
    "\n",
    "plot_image_sequence(data_X[data_y == 0], n=20, imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot faces of Jesse\n",
    "\n",
    "plot_image_sequence(data_X[data_y == 1], n=30, imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot faces of Mila\n",
    "\n",
    "plot_image_sequence(data_X[data_y == 2], n=30, imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4. Store Preprocessed data (optional)\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\". Feel free to use this to store intermediary results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "# prep_path = '/kaggle/working/prepped_data/'\n",
    "# if not os.path.exists(prep_path):\n",
    "#     os.mkdir(prep_path)\n",
    "    \n",
    "# np.save(os.path.join(prep_path, 'train_X.npy'), train_X)\n",
    "# np.save(os.path.join(prep_path, 'train_y.npy'), train_y)\n",
    "# np.save(os.path.join(prep_path, 'test_X.npy'), test_X)\n",
    "\n",
    "# load preprocessed data\n",
    "# prep_path = '/kaggle/working/prepped_data/'\n",
    "# if not os.path.exists(prep_path):\n",
    "#     os.mkdir(prep_path)\n",
    "# train_X = np.load(os.path.join(prep_path, 'train_X.npy'))\n",
    "# train_y = np.load(os.path.join(prep_path, 'train_y.npy'))\n",
    "# test_X = np.load(os.path.join(prep_path, 'test_X.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to rock!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Validation Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets using stratified sampling\n",
    "train_X, validation_X, train_y, validation_y = train_test_split(\n",
    "    data_X, data_y, test_size=0.2, random_state=42, stratify=data_y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_X)}\")\n",
    "print(f\"Validation set size: {len(validation_X)}\")\n",
    "\n",
    "# Show class distribution\n",
    "train_classes, train_counts = np.unique(train_y, return_counts=True)\n",
    "val_classes, val_counts = np.unique(validation_y, return_counts=True)\n",
    "\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(\"Class\\tCount\\tPercentage\")\n",
    "for cls, count in zip(train_classes, train_counts):\n",
    "    print(f\"{cls}\\t{count}\\t{count/len(train_y)*100:.1f}%\")\n",
    "\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "print(\"Class\\tCount\\tPercentage\")\n",
    "for cls, count in zip(val_classes, val_counts):\n",
    "    print(f\"{cls}\\t{count}\\t{count/len(validation_y)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Representations\n",
    "## 1.0. Example: Identify feature extractor\n",
    "Our example feature extractor doesn't actually do anything... It just returns the input:\n",
    "$$\n",
    "\\forall x : f(x) = x.\n",
    "$$\n",
    "\n",
    "It does make for a good placeholder and baseclass ;)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityFeatureExtractor:\n",
    "    \"\"\"A simple function that returns the input\"\"\"\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Baseline 1: HOG feature extractor\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOGFeatureExtractor:\n",
    "    \"\"\"TODO: this feature extractor is under construction\"\"\"\n",
    "    def __init__(self, **params):\n",
    "        self.params = {\n",
    "            'orientations': 8,\n",
    "            'pixels_per_cell': (4, 4),\n",
    "            'cells_per_block': (2, 2),\n",
    "            'block_norm': 'L2-Hys'\n",
    "        }\n",
    "        self.params.update(params)\n",
    "        \n",
    "    def transform(self, X: List[np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"Calculate features using Histogram of Oriented Gradients and its visualisation\"\"\"\n",
    "        hog_features = []\n",
    "        for img in X:\n",
    "            if img.dtype != np.uint8:\n",
    "                img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            \n",
    "            if len(img.shape) == 3:\n",
    "                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray_img = img\n",
    "            feat = hog(gray_img, \n",
    "                      orientations=self.params['orientations'],\n",
    "                      pixels_per_cell=self.params['pixels_per_cell'],\n",
    "                      cells_per_block=self.params['cells_per_block'],\n",
    "                      block_norm=self.params['block_norm'],\n",
    "                      visualize=False)\n",
    "            hog_features.append(feat)\n",
    "        return np.array(hog_features)   \n",
    "    \n",
    "    def visualize(self, X: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        \"\"\"Generate HOG visualizations\"\"\"\n",
    "        images_per_row: int = 5\n",
    "        hog_images = []\n",
    "        for img in X:\n",
    "            if len(img.shape) == 3:\n",
    "                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray_img = img\n",
    "            _, hog_img = hog(gray_img, \n",
    "                           orientations=self.params['orientations'],\n",
    "                           pixels_per_cell=self.params['pixels_per_cell'],\n",
    "                           cells_per_block=self.params['cells_per_block'],\n",
    "                           block_norm=self.params['block_norm'],\n",
    "                           visualize=True)\n",
    "            hog_images.append(hog_img)\n",
    "\n",
    "        n_images = len(hog_images)\n",
    "        n_rows = (n_images + images_per_row - 1) // images_per_row\n",
    "        plt.figure(figsize=(15, 3 * n_rows))\n",
    "        \n",
    "        for i, hog_img in enumerate(hog_images):\n",
    "            plt.subplot(n_rows, images_per_row, i + 1)\n",
    "            plt.imshow(hog_img, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"HOG {i+1}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = HAARPreprocessor(path='../../tmp', face_size=FACE_SIZE)\n",
    "data_X = preprocessor(train)\n",
    "\n",
    "hog_extractor = HOGFeatureExtractor(orientations=9, pixels_per_cell=(16, 16))\n",
    "normalized_faces, _ = preprocessor.normalize_size(data_X)\n",
    "hog_features = hog_extractor.transform(normalized_faces)\n",
    "hog_images = hog_extractor.visualize(normalized_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Alternative Baseline 2: Scale Invariant Feature Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIFTFeatureExtractor:\n",
    "    \"\"\"Feature extraction using Scale Invariant Feature Transform (SIFT)\"\"\"\n",
    "    def __init__(self, **params):\n",
    "        self.params = params\n",
    "        self.sift = cv2.SIFT_create(**params)\n",
    "        \n",
    "    def extract_descriptors(self, X: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        \"\"\"Calculate features using Scale Invariant Feature Transform\"\"\"\n",
    "        descriptors_list = []\n",
    "        for img in X:\n",
    "            if img.dtype != np.uint8:\n",
    "                img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            if len(img.shape) == 3:\n",
    "                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray_img = img\n",
    "            _, descriptors = self.sift.detectAndCompute(gray_img, None)\n",
    "            if descriptors is None:\n",
    "                descriptors = np.zeros((0, 128), dtype=np.float32)\n",
    "            descriptors_list.append(descriptors)\n",
    "        return descriptors_list\n",
    "\n",
    "    def visualize_keypoints(self, X: List[np.ndarray], images_per_row: int = 5):\n",
    "        \"\"\"Visualize SIFT keypoints on images\"\"\"\n",
    "        keypoints_list = []\n",
    "        for img in X:\n",
    "            if len(img.shape) == 3:\n",
    "                gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                gray_img = img\n",
    "            keypoints, _ = self.sift.detectAndCompute(gray_img, None)\n",
    "            keypoints_list.append(keypoints)\n",
    "        \n",
    "        num_images = len(X)\n",
    "        num_rows = (num_images + images_per_row - 1) // images_per_row\n",
    "        plt.figure(figsize=(15, 3 * num_rows))\n",
    "        \n",
    "        for i, (img, kps) in enumerate(zip(X, keypoints_list)):\n",
    "            plt.subplot(num_rows, images_per_row, i + 1)\n",
    "            img_with_kps = cv2.drawKeypoints(img, kps, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "            img_with_kps = cv2.cvtColor(img_with_kps, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(img_with_kps)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"SIFT Keypoints {i+1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_extractor = SIFTFeatureExtractor()\n",
    "descriptors_list = sift_extractor.extract_descriptors(normalized_faces)\n",
    "sift_extractor.visualize_keypoints(normalized_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. t-SNE Plots\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureVisualizer:    \n",
    "    @staticmethod\n",
    "    def plot_tsne(features: np.ndarray, labels: np.ndarray, title: str):\n",
    "        \"\"\"Data visualisation using T-sne\"\"\"\n",
    "        tsne = TSNE(n_components=2, perplexity=15, random_state=123)\n",
    "        tsne_2d = tsne.fit_transform(features)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        scatter = plt.scatter(tsne_2d[:, 0], tsne_2d[:, 1], c=labels, cmap='tab10')\n",
    "        unique_labels = np.unique(labels)\n",
    "        handles = [mpatches.Patch(color=scatter.cmap(scatter.norm(label)), label=str(label)) \n",
    "                  for label in unique_labels]\n",
    "        plt.legend(handles=handles, title=\"Class\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def build_codebook(descriptors_list: List[np.ndarray], n_clusters: int = 128):\n",
    "        \"\"\"Combine descriptors and create codebook for Bag-of-Words approach\"\"\"\n",
    "        all_descriptors = np.vstack([desc for desc in descriptors_list if desc.size > 0])\n",
    "        kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=123)\n",
    "        kmeans.fit(all_descriptors)\n",
    "        return kmeans\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_bow_histograms(descriptors_list: List[np.ndarray], kmeans) -> np.ndarray:\n",
    "        \"\"\"Compute Bag-of-Words histograms\"\"\"\n",
    "        n_clusters = kmeans.n_clusters\n",
    "        histograms = []\n",
    "        for desc in descriptors_list:\n",
    "            if desc.size == 0:\n",
    "                hist = np.zeros(n_clusters)\n",
    "            else:\n",
    "                words = kmeans.predict(desc)\n",
    "                hist, _ = np.histogram(words, bins=np.arange(n_clusters + 1))\n",
    "                hist = hist.astype(float)\n",
    "                if hist.sum() > 0:\n",
    "                    hist /= hist.sum()\n",
    "            histograms.append(hist)\n",
    "        return np.array(histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = FeatureVisualizer()\n",
    "labels = train['class'].to_numpy()\n",
    "visualizer.plot_tsne(hog_features, labels, \"t-SNE of HOG Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = visualizer.build_codebook(descriptors_list, n_clusters=128)\n",
    "sift_histograms = visualizer.compute_bow_histograms(descriptors_list, kmeans)\n",
    "visualizer.plot_tsne(sift_histograms, labels, \"t-SNE of SIFT Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Discussion\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Baseline 2: PCA feature extractor\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance_explained(faces: List[np.ndarray], whiten: bool) -> None:\n",
    "    \"\"\"\n",
    "    Plot variance - number of PCs.\n",
    "    \"\"\"\n",
    "    face_data = np.array([face.flatten() for face in faces])\n",
    "    max_components = min(face_data.shape[0], face_data.shape[1])\n",
    "    pca = PCA(n_components=max_components, whiten=whiten)\n",
    "    pca.fit(face_data)\n",
    "    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(np.arange(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='-')\n",
    "    plt.xlabel(\"Number of Principal Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance\")\n",
    "    plt.title(\"Explained Variance vs. Number of Principal Components\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAFeatureExtractor(IdentityFeatureExtractor):\n",
    "    \"\"\"TODO: this feature extractor is under construction\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components: int, whiten: bool):\n",
    "        self.pca = PCA(n_components=n_components, whiten=whiten)\n",
    "        self.mean_face = None\n",
    "        self.eigenvectors = None\n",
    "\n",
    "    def fit(self, faces: List[np.array]):\n",
    "        \"\"\"\n",
    "        Performs PCA give the number of principle components.\n",
    "        \"\"\"\n",
    "        face_data = np.array([face.flatten() for face in faces])\n",
    "        self.pca.fit(face_data)\n",
    "        self.mean_face = self.pca.mean_\n",
    "        self.eigenvectors = self.pca.components_\n",
    "\n",
    "    def transform(self, faces: List[np.array]) -> List[np.array]:\n",
    "        \"\"\"\n",
    "        Transform original face images to the PCA space.\n",
    "        \"\"\"\n",
    "        face_data = np.array([face.flatten() for face in faces])\n",
    "        projections = self.pca.transform(face_data)\n",
    "        return projections\n",
    "\n",
    "    def fit_transform(self, faces: List[np.array]) -> List[np.array]:\n",
    "        \"\"\"\n",
    "        Fit PCA on the data at first then transform the faces to the PCA space.\n",
    "        \"\"\"\n",
    "        self.fit(faces)\n",
    "        projections = self.transform(faces)\n",
    "        return projections\n",
    "    \n",
    "    def inverse_transform(self, projections: np.array) -> List[np.array]:\n",
    "        \"\"\"\n",
    "        Convert projections to the original image space.\n",
    "        \"\"\"\n",
    "        reconstructed = np.dot(projections, self.eigenvectors) + self.mean_face\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_to_images(vectors: List[np.array], std_shape: tuple) -> List[np.array]:\n",
    "    \"\"\"\n",
    "    Change 1D vectors to 2D images for visualization.\n",
    "\n",
    "    std_shape: tuple(H, W, C)\n",
    "        Shape of the target image.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for vector in vectors:\n",
    "        image = vector.reshape(std_shape[0], std_shape[1], std_shape[2])\n",
    "        image_shifted = image - np.min(image)\n",
    "        image_scaled = 255 * (image_shifted / np.max(image_shifted))\n",
    "        image_display = np.round(image_scaled).astype(np.uint8)\n",
    "        images.append(image_display)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_shape = (train_X.shape[1], train_X.shape[2], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_explained(train_X, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCAFeatureExtractor(50, False)\n",
    "projections = pca.fit_transform(train_X)\n",
    "reconstructed_vectors = pca.inverse_transform(projections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Eigenface Plots\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenfaces = vectors_to_images(pca.eigenvectors, std_shape)\n",
    "show_faces(eigenfaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Feature Space Plots\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_faces = vectors_to_images(reconstructed_vectors, std_shape)\n",
    "show_faces(reconstructed_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Discussion\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation Metrics\n",
    "## 2.0. Example: Accuracy\n",
    "As example metric we take the accuracy. Informally, accuracy is the proportion of correct predictions over the total amount of predictions. It is used a lot in classification but it certainly has its disadvantages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(true_labels, predictions, class_names=None, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance and plot confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - true_labels: ground truth labels\n",
    "    - predictions: model predicted labels\n",
    "    - class_names: list of class names (optional)\n",
    "    - model_name: name for labeling the confusion matrix plot\n",
    "    \"\"\"\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"\\n[{model_name}] Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(f\"\\n[{model_name}] Classification Report:\\n\", classification_report(true_labels, predictions))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    print(f\"[{model_name}] Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Plot Confusion Matrix Heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names if class_names else sorted(set(true_labels)),\n",
    "                yticklabels=class_names if class_names else sorted(set(true_labels)))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifiers\n",
    "## 3.0. Example: The *'not so smart'* classifier\n",
    "This random classifier is not very complicated. It makes predictions at random, based on the distribution obseved in the training set. **It thus assumes** that the class labels of the test set will be distributed similarly to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomClassificationModel:\n",
    "    \"\"\"Random classifier, draws a random sample based on class distribution observed \n",
    "    during training.\"\"\"\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Adjusts the class ratio instance variable to the one observed in y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor\n",
    "            Training set\n",
    "        y : array\n",
    "            Training set labels\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : RandomClassificationModel\n",
    "        \"\"\"\n",
    "        \n",
    "        self.classes, self.class_ratio = np.unique(y, return_counts=True)\n",
    "        self.class_ratio = self.class_ratio / self.class_ratio.sum()\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Samples labels for the input data. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : tensor\n",
    "            dataset\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_star : array\n",
    "            'Predicted' labels\n",
    "        \"\"\"\n",
    "\n",
    "        np.random.seed(0)\n",
    "        return np.random.choice(self.classes, size = X.shape[0], p=self.class_ratio)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeModel:\n",
    "    def __init__(self, max_depth: int = None, random_state: int = None):\n",
    "        \"\"\"\n",
    "        Initialization.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.model = DecisionTreeClassifier(max_depth=self.max_depth,\n",
    "                                            random_state=self.random_state)\n",
    "    \n",
    "    def fit(self, faces: np.array, labels: np.array):\n",
    "        \"\"\"\n",
    "        Fit the Decision Tree model.\n",
    "\n",
    "        Parameters:\n",
    "        - faces: \n",
    "            2D np.array or tensor with shape [n_samples, n_features]. Each face should be represented as a 1D vector.\n",
    "        - labels:\n",
    "            1D np.array containing the class labels.\n",
    "        \"\"\"\n",
    "        faces = np.array([face.flatten() for face in faces])\n",
    "        self.model.fit(faces, labels)\n",
    "    \n",
    "    def predict(self, faces: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Predict class for faces using the trained Decision Tree model.\n",
    "\n",
    "        Parameters:\n",
    "        - faces:\n",
    "            2D np.array or tensor with shape [n_samples, n_features]. Each face should be represented as a 1D vector.\n",
    "\n",
    "        Returns:\n",
    "        - np.array: The predicted labels for all input faces.\n",
    "        \"\"\"\n",
    "        faces = np.array([face.flatten() for face in faces])\n",
    "        return self.model.predict(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestModel:\n",
    "    def __init__(self, n_estimators: int = 100, max_depth: int = None, random_state: int = None):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.random_state = random_state\n",
    "        self.model = RandomForestClassifier(n_estimators=self.n_estimators,\n",
    "                                            max_depth=self.max_depth,\n",
    "                                            random_state=self.random_state)\n",
    "    \n",
    "    def fit(self, faces: np.array, labels: np.array):\n",
    "        \"\"\"\n",
    "        Fit the model.\n",
    "\n",
    "        Parameters:\n",
    "        faces: \n",
    "            2d np.array or tensor with shape [n_sample, n_feature], namely each face should be\n",
    "            represented with 1D vectors\n",
    "        labels:\n",
    "            1d np.array containing labels.\n",
    "        \"\"\"\n",
    "        faces = np.array([face.flatten() for face in faces])\n",
    "        self.model.fit(faces, labels)\n",
    "    \n",
    "    def predict(self, faces: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Predict class for faces.\n",
    "\n",
    "        Parameters:\n",
    "        faces: \n",
    "            2d np.array or tensor with shape [n_sample, n_feature], namely each face should be\n",
    "            represented with 1D vectors\n",
    "\n",
    "        Return:\n",
    "            The predicted labels of all the input faces.\n",
    "        \"\"\"\n",
    "        faces = np.array([face.flatten() for face in faces])\n",
    "        return self.model.predict(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMClassifier:\n",
    "    \"\"\"Classifier using Support Vector Machine (SVM) algorithm\"\"\"\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        \"\"\"\n",
    "        Initialize SVM classifier with given parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        C: float (default=1.0) - regulatisation parameter\n",
    "        kernel: str (default='rbf') - specify the kernel type\n",
    "        gamma: str or float (default='scale') \n",
    "        random_state: int (default='42')\n",
    "        and more\n",
    "        \"\"\"\n",
    "        default_params = {\n",
    "            'C': 1.0,\n",
    "            'kernel': 'rbf',\n",
    "            'gamma': 'scale',\n",
    "            'random_state': 42\n",
    "        }\n",
    "        default_params.update(params)\n",
    "        self.model = SVC(**default_params)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the SVM classifier on the given data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : np.ndarray\n",
    "            Feature matrix of shape (n_samples, n_features)\n",
    "        y : np.ndarray\n",
    "            Target labels of shape (n_samples,)\n",
    "        \"\"\"\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.model.fit(X_scaled, y)\n",
    "        self.is_trained = True\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict class labels for samples using trained model\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: np.ndarray\n",
    "            Feature matrix of shape(face) (n_samples, n_features)\n",
    "        \n",
    "        Returns: \n",
    "        --------\n",
    "        np.ndarray - predicted class label of faces\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")  \n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. CNN (ImageNet Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    \"\"\"\n",
    "    A CNN based on mobilenet_v2 model.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=3, lr=0.001, num_epochs=10, batch_size=16):\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = models.mobilenet_v2(pretrained=True)\n",
    "        \n",
    "        # Freeze pretrained layers' parameters.\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Contenate a classification head after ImageNet, only this part is trained.\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.model.last_channel, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.num_classes)\n",
    "        )\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = torch.device(\"mps\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.is_trained = False\n",
    "        \n",
    "        # Normalize to the size required by mobileNet\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Train the CNN classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        X : np.ndarray\n",
    "            Array of images with shape (n_samples, H, W, C).\n",
    "        y : np.ndarray\n",
    "            Array of target labels with shape (n_samples,).\n",
    "        \"\"\"\n",
    "        # Load the data to Dataset for training.\n",
    "        class ImageDataset(Dataset):\n",
    "            def __init__(self, images, labels, transform=None):\n",
    "                self.images = images\n",
    "                self.labels = labels\n",
    "                self.transform = transform\n",
    "                \n",
    "            def __len__(self):\n",
    "                return len(self.images)\n",
    "            \n",
    "            def __getitem__(self, idx: int) -> tuple:\n",
    "                \"\"\"\n",
    "                Output the image given the index.\n",
    "                \"\"\"\n",
    "                image = self.images[idx]\n",
    "                image = Image.fromarray(image)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                label = int(self.labels[idx])\n",
    "                return image, label\n",
    "        \n",
    "        dataset = ImageDataset(X, y, transform=self.transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataset)\n",
    "            epoch_acc = correct / total\n",
    "            print(f\"Epoch {epoch+1}/{self.num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "        \n",
    "        self.is_trained = True\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        if not self.is_trained:\n",
    "            raise RuntimeError(\"Model has not been trained yet. Call fit() first.\")\n",
    "        \n",
    "        # Create a dataset for inference.\n",
    "        class PredictDataset(Dataset):\n",
    "            def __init__(self, images, transform=None):\n",
    "                self.images = images\n",
    "                self.transform = transform\n",
    "                \n",
    "            def __len__(self):\n",
    "                return len(self.images)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                image = self.images[idx]\n",
    "                image = Image.fromarray(image)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                return image\n",
    "        \n",
    "        dataset = PredictDataset(X, transform=self.transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for images in dataloader:\n",
    "                images = images.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        return np.array(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiments\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> Do <i>NOT</i> use this section to keep track of every little change you make in your code! Instead, highlight the most important findings and the major (best) pipelines that you've discovered.  \n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## 4.0. Example: basic pipeline\n",
    "The basic pipeline takes any input and samples a label based on the class label distribution of the training set. As expected the performance is very poor, predicting approximately 1/4 correctly on the training set. There is a lot of room for improvement but this is left to you ;). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = IdentityFeatureExtractor() \n",
    "classifier = RandomClassificationModel()\n",
    "\n",
    "# train the model on the features\n",
    "classifier.fit(feature_extractor(train_X), train_y)\n",
    "\n",
    "# model/final pipeline\n",
    "model = lambda X: classifier(feature_extractor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance of the model on the training set\n",
    "train_y_star = model(validation_X)\n",
    "\n",
    "\"The performance on the training set is {:.2f}. This however, does not tell us much about the actual performance (generalisability).\".format(\n",
    "    accuracy_score(validation_y, train_y_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels for the test set \n",
    "test_y_star = model(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 PCA + DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCAFeatureExtractor(50, False)\n",
    "projections = pca.fit_transform(train_X)\n",
    "cls_dt = DecisionTreeModel()\n",
    "cls_dt.fit(projections, train_y)\n",
    "\n",
    "validation_X_pca = pca.transform(validation_X)\n",
    "predictions = cls_dt.predict(validation_X_pca)\n",
    "accuracy_score(validation_y, predictions)\n",
    "evaluate_model(validation_y, predictions, class_names=[\"Michael\", \"Sarah\", \"Unknown\"], model_name=\"PCA + DecisionTree\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 PCA + RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCAFeatureExtractor(50, False)\n",
    "projections = pca.fit_transform(train_X)\n",
    "cls_rf = RandomForestModel()\n",
    "cls_rf.fit(projections, train_y)\n",
    "\n",
    "validation_X_pca = pca.transform(validation_X)\n",
    "predictions = cls_rf.predict(validation_X_pca)\n",
    "accuracy_score(validation_y, predictions)\n",
    "\n",
    "evaluate_model(validation_y, predictions, class_names=[\"Michael\", \"Sarah\", \"Unknown\"], model_name=\"PCA + RandomForest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 PCA + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCAFeatureExtractor(50, False)\n",
    "projections = pca.fit_transform(train_X)\n",
    "svm = SVMClassifier(C=0.1, gamma = 0.001 , kernel='rbf')\n",
    "svm.fit(projections, train_y)\n",
    "\n",
    "validation_X_pca = pca.transform(validation_X)\n",
    "predictions = svm.predict(validation_X_pca)\n",
    "accuracy = accuracy_score(validation_y, predictions)\n",
    "print(f\"\\n Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "evaluate_model(validation_y, predictions, class_names=[\"Michael\", \"Sarah\", \"Unknown\"], model_name=\"PCA + SVM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 PCA + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCAFeatureExtractor(50, False)\n",
    "projections = pca.fit_transform(train_X)\n",
    "reconstructed_vectors = pca.inverse_transform(projections)\n",
    "reconstructed_faces = vectors_to_images(reconstructed_vectors, std_shape)\n",
    "\n",
    "cnn_clf = CNN()\n",
    "cnn_clf.fit(reconstructed_faces, train_y)\n",
    "\n",
    "validation_X_pca = pca.transform(validation_X)\n",
    "reconstructed_vectors = pca.inverse_transform(validation_X_pca)\n",
    "reconstructed_faces = vectors_to_images(reconstructed_vectors, std_shape)\n",
    "predictions = cnn_clf.predict(reconstructed_faces)\n",
    "accuracy = accuracy_score(validation_y, predictions)\n",
    "print(f\"\\n Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "evaluate_model(validation_y, predictions, class_names=[\"Michael\", \"Sarah\", \"Unknown\"], model_name=\"PCA + CNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 HOG + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_extractor = HOGFeatureExtractor(orientations=9, pixels_per_cell=(16, 16))\n",
    "X_train_hog = hog_extractor.transform(train_X)\n",
    "X_val_hog = hog_extractor.transform(validation_X)\n",
    "svm = SVMClassifier(C=10, kernel='rbf')\n",
    "svm.fit(X_train_hog, train_y)\n",
    "predictions = svm.predict(X_val_hog)\n",
    "accuracy = accuracy_score(validation_y, predictions)\n",
    "print(f\"\\n Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "evaluate_model(validation_y, predictions, class_names=[\"Michael\", \"Sarah\", \"Unknown\"], model_name=\"HOG + SVM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Publishing best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy().drop('img', axis = 1)\n",
    "submission['class'] = test_y_star\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Discussion\n",
    "...\n",
    "\n",
    "In summary we contributed the following: \n",
    "* \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
